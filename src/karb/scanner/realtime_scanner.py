"""Real-time market scanner using WebSocket streaming."""

import asyncio
import json
from dataclasses import dataclass, field
from datetime import datetime, timezone
from decimal import Decimal
from pathlib import Path
from typing import Callable, Optional

from karb.api.gamma import GammaClient
from karb.api.models import Market
from karb.api.websocket import (
    OrderBookUpdate,
    PriceChange,
    WebSocketClient,
)
from karb.config import get_settings
from karb.notifications.slack import get_notifier
from karb.utils.logging import get_logger

log = get_logger(__name__)

# Shared state files for dashboard
STATS_FILE = Path.home() / ".karb" / "scanner_stats.json"
ALERTS_FILE = Path.home() / ".karb" / "scanner_alerts.json"

# Maximum assets per WebSocket connection
MAX_ASSETS_PER_WS = 500
# Default number of WebSocket connections
DEFAULT_WS_CONNECTIONS = 6


@dataclass
class MarketPrices:
    """Tracks current prices for a market's YES and NO tokens."""
    market: Market
    yes_best_bid: Optional[Decimal] = None
    yes_best_ask: Optional[Decimal] = None
    no_best_bid: Optional[Decimal] = None
    no_best_ask: Optional[Decimal] = None
    # Size available at best ask prices
    yes_best_ask_size: Optional[Decimal] = None
    no_best_ask_size: Optional[Decimal] = None

    @property
    def combined_ask(self) -> Optional[Decimal]:
        """Cost to buy both YES and NO at best ask."""
        if self.yes_best_ask is None or self.no_best_ask is None:
            return None
        return self.yes_best_ask + self.no_best_ask

    @property
    def arbitrage_profit(self) -> Optional[Decimal]:
        """Potential profit from arbitrage (1 - combined_ask)."""
        combined = self.combined_ask
        if combined is None:
            return None
        return Decimal("1") - combined

    @property
    def has_arbitrage(self) -> bool:
        """Check if arbitrage opportunity exists."""
        profit = self.arbitrage_profit
        if profit is None:
            return False
        settings = get_settings()
        return profit > Decimal(str(settings.min_profit_threshold))


@dataclass
class ArbitrageAlert:
    """Alert for detected arbitrage opportunity."""
    market: Market
    yes_ask: Decimal
    no_ask: Decimal
    combined_cost: Decimal
    profit_pct: Decimal
    timestamp: float
    # Size available at ask prices
    yes_size_available: Decimal = Decimal("0")
    no_size_available: Decimal = Decimal("0")


# Callback type for arbitrage alerts
ArbitrageCallback = Callable[[ArbitrageAlert], None]


class RealtimeScanner:
    """
    Real-time market scanner using WebSocket streaming.

    Instead of polling, this scanner:
    1. Loads markets from Gamma API
    2. Subscribes to WebSocket for real-time price updates
    3. Triggers callbacks instantly when arbitrage is detected

    Supports multiple WebSocket connections to monitor more markets.
    """

    def __init__(
        self,
        on_arbitrage: Optional[ArbitrageCallback] = None,
        min_liquidity: Optional[float] = None,
        max_days_until_resolution: Optional[int] = None,
        num_connections: Optional[int] = None,
    ) -> None:
        settings = get_settings()

        self.gamma = GammaClient()

        # Use settings from config, allow override via constructor
        self.min_liquidity = min_liquidity if min_liquidity is not None else settings.min_liquidity_usd
        self.max_days_until_resolution = (
            max_days_until_resolution if max_days_until_resolution is not None
            else settings.max_days_until_resolution
        )
        self.num_connections = num_connections if num_connections is not None else settings.num_ws_connections

        # Calculate max markets based on connections
        # Each connection can handle 500 assets = 250 markets (YES + NO tokens)
        self.max_markets = (MAX_ASSETS_PER_WS // 2) * self.num_connections

        # Create multiple WebSocket clients
        self.ws_clients: list[WebSocketClient] = []
        for i in range(self.num_connections):
            client = WebSocketClient(
                on_book=self._on_book_update,
                on_price_change=self._on_price_change,
            )
            self.ws_clients.append(client)

        self._on_arbitrage = on_arbitrage

        # State
        self._markets: dict[str, Market] = {}  # market_id -> Market
        self._token_to_market: dict[str, str] = {}  # token_id -> market_id
        self._market_prices: dict[str, MarketPrices] = {}  # market_id -> MarketPrices
        self._running = False

        # Track active opportunities for duration calculation
        self._active_opportunities: dict[str, datetime] = {}  # market_id -> first_seen

        # Stats
        self._price_updates = 0
        self._arbitrage_alerts = 0

        log.info(
            "Scanner initialized",
            num_connections=self.num_connections,
            max_markets=self.max_markets,
            min_liquidity=self.min_liquidity,
            max_days=self.max_days_until_resolution,
        )

    async def load_markets(self) -> list[Market]:
        """Load active markets from Gamma API."""
        log.info("Loading markets from Gamma API...")

        markets = await self.gamma.fetch_all_active_markets(
            min_liquidity=self.min_liquidity,
            max_days_until_resolution=self.max_days_until_resolution,
        )

        # Sort by liquidity and take top N
        markets.sort(key=lambda m: m.liquidity, reverse=True)
        markets = markets[:self.max_markets]

        # Build lookup tables
        self._markets = {}
        self._token_to_market = {}
        self._market_prices = {}

        for market in markets:
            self._markets[market.id] = market
            self._token_to_market[market.yes_token.token_id] = market.id
            self._token_to_market[market.no_token.token_id] = market.id
            self._market_prices[market.id] = MarketPrices(market=market)

        log.info(
            "Markets loaded",
            count=len(markets),
            min_liquidity=self.min_liquidity,
            max_days=self.max_days_until_resolution,
        )

        return markets

    async def subscribe_to_markets(self) -> None:
        """Subscribe to WebSocket updates for all loaded markets."""
        # Clear old subscriptions for fresh start
        for client in self.ws_clients:
            client._subscribed_assets.clear()

        # Collect all token IDs (YES and NO for each market)
        token_ids = []
        for market in self._markets.values():
            token_ids.append(market.yes_token.token_id)
            token_ids.append(market.no_token.token_id)

        log.info("Subscribing to tokens", count=len(token_ids), connections=len(self.ws_clients))

        # Distribute tokens across connections
        # Each connection can handle MAX_ASSETS_PER_WS (500) tokens
        for i, client in enumerate(self.ws_clients):
            start = i * MAX_ASSETS_PER_WS
            end = start + MAX_ASSETS_PER_WS
            batch = token_ids[start:end]
            if batch:
                log.info(f"Connection {i+1}: subscribing to {len(batch)} tokens")
                await client.subscribe(batch)

    def _on_book_update(self, update: OrderBookUpdate) -> None:
        """Handle orderbook snapshot update."""
        # Get size at best ask price
        best_ask_size = None
        if update.asks:
            best_ask_price = min(a.price for a in update.asks)
            for a in update.asks:
                if a.price == best_ask_price:
                    best_ask_size = a.size
                    break

        self._update_prices(
            update.asset_id,
            update.best_bid,
            update.best_ask,
            best_ask_size,
        )

    def _on_price_change(self, change: PriceChange) -> None:
        """Handle real-time price change."""
        self._price_updates += 1
        # For price changes, get size from cached orderbook
        best_ask_size = None
        # Search for orderbook across all WebSocket clients
        orderbook = None
        for client in self.ws_clients:
            orderbook = client.get_orderbook(change.asset_id)
            if orderbook:
                break
        if orderbook and orderbook.asks:
            best_ask_price = min(a.price for a in orderbook.asks)
            for a in orderbook.asks:
                if a.price == best_ask_price:
                    best_ask_size = a.size
                    break

        self._update_prices(
            change.asset_id,
            change.best_bid,
            change.best_ask,
            best_ask_size,
        )

    def _update_prices(
        self,
        token_id: str,
        best_bid: Optional[Decimal],
        best_ask: Optional[Decimal],
        best_ask_size: Optional[Decimal] = None,
    ) -> None:
        """Update prices for a token and check for arbitrage."""
        market_id = self._token_to_market.get(token_id)
        if not market_id:
            return

        market = self._markets.get(market_id)
        if not market:
            return

        prices = self._market_prices.get(market_id)
        if not prices:
            return

        # Update the appropriate side
        if token_id == market.yes_token.token_id:
            prices.yes_best_bid = best_bid
            prices.yes_best_ask = best_ask
            if best_ask_size is not None:
                prices.yes_best_ask_size = best_ask_size
        elif token_id == market.no_token.token_id:
            prices.no_best_bid = best_bid
            prices.no_best_ask = best_ask
            if best_ask_size is not None:
                prices.no_best_ask_size = best_ask_size

        # Check for arbitrage
        self._check_arbitrage(prices)

    def _check_arbitrage(self, prices: MarketPrices) -> None:
        """Check if market has arbitrage opportunity and trigger alert."""
        # Track near-misses for diagnostics (profit > 0 but below threshold)
        profit = prices.arbitrage_profit
        if profit is not None and profit > Decimal("0"):
            settings = get_settings()
            # Log near-misses (within 0.5% of threshold) at debug level
            if profit < Decimal(str(settings.min_profit_threshold)):
                if profit > Decimal(str(settings.min_profit_threshold)) - Decimal("0.005"):
                    log.debug(
                        "Near-miss arbitrage",
                        market=prices.market.question[:40],
                        profit=f"{float(profit) * 100:.3f}%",
                        threshold=f"{settings.min_profit_threshold * 100:.1f}%",
                        combined=f"${float(prices.combined_ask):.4f}" if prices.combined_ask else "N/A",
                    )
                # Track the best near-miss for stats logging
                if not hasattr(self, '_best_near_miss') or profit > self._best_near_miss:
                    self._best_near_miss = profit
                    self._best_near_miss_market = prices.market.question[:40]

        if not prices.has_arbitrage:
            # If this market had an active opportunity that just ended, log it
            market_id = prices.market.id
            if market_id in self._active_opportunities:
                first_seen = self._active_opportunities.pop(market_id)
                duration_secs = (datetime.now(timezone.utc) - first_seen).total_seconds()
                log.info(
                    "Opportunity closed",
                    market=prices.market.question[:40],
                    duration_secs=f"{duration_secs:.1f}s",
                )
            return

        # Check resolution date - skip markets that resolve too far in the future
        settings = get_settings()
        if prices.market.end_date:
            now = datetime.now(timezone.utc)
            # Make end_date timezone-aware if it isn't
            end_date = prices.market.end_date
            if end_date.tzinfo is None:
                end_date = end_date.replace(tzinfo=timezone.utc)
            days_until = (end_date - now).days
            if days_until > settings.max_days_until_resolution:
                log.debug(
                    "Skipping arbitrage - resolution too far",
                    market=prices.market.question[:30],
                    days_until=days_until,
                    max_days=settings.max_days_until_resolution,
                )
                return

        # We have an opportunity!
        combined = prices.combined_ask
        profit = prices.arbitrage_profit

        if combined is None or profit is None:
            return

        self._arbitrage_alerts += 1

        # Track when opportunity first appeared
        market_id = prices.market.id
        now = datetime.now(timezone.utc)
        if market_id not in self._active_opportunities:
            self._active_opportunities[market_id] = now
        first_seen = self._active_opportunities[market_id]
        duration_secs = (now - first_seen).total_seconds()

        alert = ArbitrageAlert(
            market=prices.market,
            yes_ask=prices.yes_best_ask or Decimal("0"),
            no_ask=prices.no_best_ask or Decimal("0"),
            combined_cost=combined,
            profit_pct=profit,
            timestamp=asyncio.get_event_loop().time(),
            yes_size_available=prices.yes_best_ask_size or Decimal("0"),
            no_size_available=prices.no_best_ask_size or Decimal("0"),
        )

        # Calculate days until resolution for logging
        days_until_resolution = None
        if prices.market.end_date:
            now = datetime.now(timezone.utc)
            end_date = prices.market.end_date
            if end_date.tzinfo is None:
                end_date = end_date.replace(tzinfo=timezone.utc)
            days_until_resolution = (end_date - now).days

        log.info(
            "ARBITRAGE DETECTED",
            market=prices.market.question[:50],
            yes_ask=f"${float(alert.yes_ask):.4f}",
            no_ask=f"${float(alert.no_ask):.4f}",
            combined=f"${float(alert.combined_cost):.4f}",
            profit=f"{float(alert.profit_pct) * 100:.2f}%",
            resolves_in=f"{days_until_resolution}d" if days_until_resolution is not None else "unknown",
            open_for=f"{duration_secs:.1f}s",
        )

        # Trigger callback FIRST - execution is time-critical
        if self._on_arbitrage:
            try:
                result = self._on_arbitrage(alert)
                if asyncio.iscoroutine(result):
                    asyncio.create_task(result)
            except Exception as e:
                log.error("Arbitrage callback error", error=str(e))

        # Save alert to file for dashboard (non-blocking, runs in background)
        loop = asyncio.get_event_loop()
        loop.run_in_executor(None, self._save_alert, alert, first_seen, duration_secs)

        # Send Slack notification (already async)
        try:
            notifier = get_notifier()
            asyncio.create_task(notifier.notify_arbitrage(
                market=prices.market.question,
                yes_ask=alert.yes_ask,
                no_ask=alert.no_ask,
                combined=alert.combined_cost,
                profit_pct=alert.profit_pct,
            ))
        except Exception as e:
            log.debug("Slack notification failed", error=str(e))

    async def run(self) -> None:
        """Run the real-time scanner."""
        self._running = True

        log.info(
            "Starting real-time scanner",
            num_connections=self.num_connections,
            max_markets=self.max_markets,
        )

        # Load markets
        await self.load_markets()

        # Connect all WebSocket clients
        for i, client in enumerate(self.ws_clients):
            await client.connect()
            log.info(f"WebSocket connection {i+1} established")

        # Subscribe to markets (distributes across connections)
        await self.subscribe_to_markets()

        # Run all WebSocket listeners plus periodic tasks
        tasks = [
            self._run_websocket_with_reconnect(i, client)
            for i, client in enumerate(self.ws_clients)
        ]
        tasks.extend([
            self._periodic_market_refresh(),
            self._periodic_stats(),
        ])
        await asyncio.gather(*tasks)

    async def _run_websocket_with_reconnect(self, conn_id: int, client: WebSocketClient) -> None:
        """Run a single WebSocket connection with automatic reconnection."""
        while self._running:
            try:
                # Listen until disconnected
                await client.listen()

            except Exception as e:
                log.error(f"WebSocket {conn_id+1} error", error=str(e))

            if not self._running:
                break

            # Reconnect with backoff
            delay = min(client._reconnect_delay, 30)
            log.info(f"Reconnecting WebSocket {conn_id+1}", delay=delay)
            await asyncio.sleep(delay)
            client._reconnect_delay = min(delay * 2, 60)

            # Reconnect
            try:
                await client.connect()
                # Re-subscribe this connection's tokens
                token_ids = list(self._token_to_market.keys())
                start = conn_id * MAX_ASSETS_PER_WS
                end = start + MAX_ASSETS_PER_WS
                batch = token_ids[start:end]
                if batch:
                    await client.subscribe(batch)
            except Exception as e:
                log.error(f"WebSocket {conn_id+1} reconnect failed", error=str(e))

    async def _periodic_market_refresh(self, interval: float = 600) -> None:
        """Periodically refresh market list (every 10 min)."""
        while self._running:
            await asyncio.sleep(interval)

            try:
                log.info("Refreshing market list...")
                old_count = len(self._markets)
                await self.load_markets()
                new_count = len(self._markets)

                # Only resubscribe if markets changed significantly
                if abs(new_count - old_count) > 10:
                    log.info("Market list changed, reconnecting all WebSockets")
                    # Close all connections to trigger reconnect
                    for client in self.ws_clients:
                        client._subscribed_assets.clear()
                        if client._ws:
                            await client._ws.close()
            except Exception as e:
                log.error("Market refresh error", error=str(e))

    async def _periodic_stats(self, interval: float = 60) -> None:
        """Log periodic statistics and write to shared state file."""
        while self._running:
            await asyncio.sleep(interval)

            stats = self.get_stats()

            # Include best near-miss in stats if available
            best_spread = None
            best_spread_market = None
            if hasattr(self, '_best_near_miss') and self._best_near_miss:
                best_spread = f"{float(self._best_near_miss) * 100:.3f}%"
                best_spread_market = getattr(self, '_best_near_miss_market', None)

            log.info(
                "Scanner stats",
                markets=stats["markets"],
                price_updates=stats["price_updates"],
                arbitrage_alerts=stats["arbitrage_alerts"],
                ws_connections=stats["ws_connections"],
                best_spread=best_spread,
            )

            # Log best near-miss market details if significant
            if best_spread and best_spread_market:
                log.debug(
                    "Best spread seen",
                    market=best_spread_market,
                    spread=best_spread,
                )

            # Write stats to file for dashboard
            self._write_stats_file(stats)

    def _write_stats_file(self, stats: dict) -> None:
        """Write stats to shared file for dashboard."""
        try:
            STATS_FILE.parent.mkdir(parents=True, exist_ok=True)
            stats["last_update"] = asyncio.get_event_loop().time()
            with open(STATS_FILE, "w") as f:
                json.dump(stats, f)
        except Exception as e:
            log.debug("Failed to write stats file", error=str(e))

    def _save_alert(
        self,
        alert: ArbitrageAlert,
        first_seen: datetime = None,
        duration_secs: float = None,
    ) -> None:
        """Save arbitrage alert to file for dashboard."""
        try:
            ALERTS_FILE.parent.mkdir(parents=True, exist_ok=True)

            # Load existing alerts
            alerts = []
            if ALERTS_FILE.exists():
                with open(ALERTS_FILE) as f:
                    alerts = json.load(f)

            # Calculate days until resolution
            days_until = None
            if alert.market.end_date:
                now = datetime.now(timezone.utc)
                end_date = alert.market.end_date
                if end_date.tzinfo is None:
                    end_date = end_date.replace(tzinfo=timezone.utc)
                days_until = (end_date - now).days

            # Include resolution date as ISO string for proper formatting
            resolution_date = None
            if alert.market.end_date:
                if alert.market.end_date.tzinfo is None:
                    resolution_date = alert.market.end_date.replace(tzinfo=timezone.utc).isoformat()
                else:
                    resolution_date = alert.market.end_date.isoformat()

            # Add new alert
            alerts.append({
                "market": alert.market.question[:60],
                "yes_ask": float(alert.yes_ask),
                "no_ask": float(alert.no_ask),
                "combined": float(alert.combined_cost),
                "profit": float(alert.profit_pct),
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "platform": "polymarket",
                "days_until_resolution": days_until,
                "resolution_date": resolution_date,
                "first_seen": first_seen.isoformat() if first_seen else None,
                "duration_secs": round(duration_secs, 1) if duration_secs is not None else None,
            })

            # Keep only last 50 alerts
            alerts = alerts[-50:]

            with open(ALERTS_FILE, "w") as f:
                json.dump(alerts, f)
        except Exception as e:
            log.debug("Failed to save alert", error=str(e))

    def stop(self) -> None:
        """Stop the scanner."""
        log.info("Stopping real-time scanner")
        self._running = False

    async def close(self) -> None:
        """Close all connections."""
        self.stop()
        for client in self.ws_clients:
            await client.close()
        await self.gamma.close()

    def get_stats(self) -> dict:
        """Get scanner statistics."""
        # Aggregate stats from all WebSocket connections
        connected = sum(1 for c in self.ws_clients if c.is_connected)
        total_subscribed = sum(c.subscribed_count for c in self.ws_clients)
        return {
            "markets": len(self._markets),
            "price_updates": self._price_updates,
            "arbitrage_alerts": self._arbitrage_alerts,
            "ws_connected": connected == len(self.ws_clients),
            "ws_connections": f"{connected}/{len(self.ws_clients)}",
            "subscribed_tokens": total_subscribed,
        }

    async def __aenter__(self) -> "RealtimeScanner":
        return self

    async def __aexit__(self, *args: object) -> None:
        await self.close()
